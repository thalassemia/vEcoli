// Global default params
params {
    experimentId = 'EXPERIMENT_ID'
    config = 'CONFIG_FILE'
}

profiles {
    gcloud {
        // Retry once with more RAM if OOM
        process.memory = {
            if ( task.exitStatus == 137 ) {
                4.GB * task.attempt
            } else {
                4.GB
            }
        }
        process.cpus = 2
        process.executor = 'google-batch'
        process.container = 'IMAGE_NAME'
        process.errorStrategy = {
            // Exit status 137 (OOM), 139 (segfault, probably in PyArrow),
            task.exitStatus in [137, 139] ? 'retry' : 'ignore' }
        google.project = 'allen-discovery-center-mcovert'
        google.location = 'us-west1'
        google.batch.spot = true
        docker.enabled = true
        params.projectRoot = '/vivarium-ecoli'
        params.publishDir = "PUBLISH_DIR"
        process.maxRetries = 1
    }
    sherlock {
        process.memory = {
            if ( task.exitStatus in [137, 140] ) {
                4.GB * task.attempt
            } else {
                4.GB
            }
        }
        process.errorStrategy = {
            // Exit status 137 (OOM), 139 (segfault, probably in PyArrow),
            // 140 (SLURM job limits), 143 (SLURM pre-emption)
            // Default value for exitStatus is max integer value, this
            // is the case for errors that leave no exit code
            ((task.exitStatus in [137, 139, 140, 143, Integer.MAX_VALUE])
            && (task.attempt <= process.maxRetries)) ? 'retry' : 'ignore' }
        process.cpus = 1
        process.executor = 'slurm'
        process.queue = 'owners'
        process.time = {
            if ( task.exitStatus == 140 ) {
                2.h * task.attempt
            } else {
                2.h
            }
        }
        process.maxRetries = 3
        params.projectRoot = "${launchDir}"
        params.publishDir = "PUBLISH_DIR"
        // Retry all jobs that fail to submit (different from fail during runtime)
        executor.submit.retry.reason = '.*'
        // Avoid polling scheduler too frequently (can cause job status mixups)
        executor.pollInterval = '5m'
        executor.queueStatInterval = '5m'
        executor.submitRateLimit = '20/min'
        executor.exitReadTimeout = '15 min'
        executor.dumpInterval = '6 min'
        executor.queueSize = 64
    }
    standard {
        process.executor = 'local'
        params.projectRoot = "${launchDir}"
        params.publishDir = "PUBLISH_DIR"
    }
}
